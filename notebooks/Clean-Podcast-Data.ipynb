{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbbc8d5-6e7c-403d-838a-2ab1e2e7cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from src.utils import get_nba_season\n",
    "\n",
    "from src.data_utils import load_clean_scores\n",
    "from src.player_utils import PlayerUtil\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 400)\n",
    "\n",
    "df = load_clean_scores([\"2023-24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38b3f3e-3a20-4939-b762-bce98990fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_player_minute_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 150\u001b[0m\n\u001b[0;32m    145\u001b[0m segment_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m    148\u001b[0m current_season \u001b[38;5;241m=\u001b[39m get_nba_season(date)\n\u001b[1;32m--> 150\u001b[0m minutes \u001b[38;5;241m=\u001b[39m \u001b[43mget_player_minute_stats\u001b[49m(df)\n\u001b[0;32m    151\u001b[0m minutes \u001b[38;5;241m=\u001b[39m minutes[minutes\u001b[38;5;241m.\u001b[39mseason_year \u001b[38;5;241m==\u001b[39m current_season]\n\u001b[0;32m    153\u001b[0m players \u001b[38;5;241m=\u001b[39m get_players_for_date(df, date)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_player_minute_stats' is not defined"
     ]
    }
   ],
   "source": [
    "# Download NLTK data (for sentence tokenization)\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "# Load SpaCy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def segment_by_semantics(text, max_tokens=50):\n",
    "    \"\"\"\n",
    "    Segments text into semantically meaningful chunks based on SpaCy's parsing.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    segments = []\n",
    "    chunk = []\n",
    "    token_count = 0\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        token_count += len(sent)\n",
    "        chunk.append(sent.text)\n",
    "        if token_count >= max_tokens:\n",
    "            segments.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "            token_count = 0\n",
    "\n",
    "    # Add any remaining sentences\n",
    "    if chunk:\n",
    "        segments.append(\" \".join(chunk))\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Define a function to clean text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes irrelevant sections and prepares text for further processing.\n",
    "    \"\"\"\n",
    "    # Remove advertisements or specific unwanted patterns\n",
    "    ad_patterns = [\n",
    "        r\"(?i)sponsored by .*\",  # Example: \"Sponsored by XYZ\"\n",
    "        r\"(?i)ad break.*\",  # Example: \"Ad break starts here\"\n",
    "        r\"http\\S+\",  # URLs\n",
    "        r\"\\[.*?\\]\",  # Content in brackets (e.g., [Music])\n",
    "    ]\n",
    "    for pattern in ad_patterns:\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Define a function to annotate entities\n",
    "def annotate_entities(sentences):\n",
    "    \"\"\"\n",
    "    Uses SpaCy's NER to detect and annotate entities.\n",
    "    Returns a list of sentences with annotated entities.\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        annotations.append({\"sentence\": sentence, \"entities\": entities})\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# Process all text files in a directory\n",
    "def process_text_files(directory):\n",
    "    \"\"\"\n",
    "    Processes all .txt files in the specified directory.\n",
    "    Cleans text, segments it into sentences, and annotates entities.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            # Clean text\n",
    "            # cleaned_text = clean_text(text)\n",
    "\n",
    "            # Segment text\n",
    "            sentences = segment_by_semantics(text)\n",
    "\n",
    "            # Annotate entities\n",
    "            annotated_sentences = annotate_entities(sentences)\n",
    "\n",
    "            # Save results\n",
    "            results.extend(\n",
    "                [\n",
    "                    {\n",
    "                        \"file_name\": file_name,\n",
    "                        \"sentence\": ann[\"sentence\"],\n",
    "                        \"word_count\": len(ann[\"sentence\"].split()),\n",
    "                        \"entities\": ann[\"entities\"],\n",
    "                    }\n",
    "                    for ann in annotated_sentences\n",
    "                ]\n",
    "            )\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_text_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Segment text\n",
    "    sentences = segment_by_semantics(text)\n",
    "\n",
    "    # Annotate entities\n",
    "    annotated_sentences = annotate_entities(sentences)\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Save results\n",
    "    results = [\n",
    "        {\n",
    "            \"file_name\": file_name,\n",
    "            \"sentence\": ann[\"sentence\"],\n",
    "            \"word_count\": len(ann[\"sentence\"].split()),\n",
    "            \"entities\": ann[\"entities\"],\n",
    "        }\n",
    "        for ann in annotated_sentences\n",
    "    ]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Directory containing text files\n",
    "directory_path = \"../data/raw/rotowire_2023_2024\"\n",
    "\n",
    "date = \"2023-12-08\"\n",
    "file_path = (\n",
    "    directory_path\n",
    "    + \"/Fantasy Basketball Waiver Wire - Adds for Week 8 2023-24_transcript_6b67bc46-0000-2bfc-bcc0-2405887bfb7c.txt\"\n",
    ")\n",
    "\n",
    "results = process_text_file(file_path)\n",
    "\n",
    "# Convert to a DataFrame for easy analysis\n",
    "segment_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "current_season = get_nba_season(date)\n",
    "\n",
    "minutes = get_player_minute_stats(df)\n",
    "minutes = minutes[minutes.season_year == current_season]\n",
    "\n",
    "players = get_players_for_date(df, date)\n",
    "players = players.merge(minutes, on=['personId', 'personName'], how='left')\n",
    "# players.sort_values(['games_over_5_minutes', 'avg_minutes_per_game'], ascending=False)\n",
    "filtered_players = players[(players['games_over_5_minutes'] >= 10) & (players['avg_minutes_per_game'] >= 10)]\n",
    "\n",
    "print(len(players))\n",
    "print(len(filtered_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb83b3c3-20af-427e-a2c9-47dffc2db6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah Shannon we saw like I mentioned Trey Murphy was a team's highest score for the Pelicans he still coming off the bench though  any concerns about that or do you think like either still a good chance he ends up playing 30 minutes a game off the bench maybe the Pokemon starting lineup at some point you know her Jones is still in there right now  yeah I mean that that 43 to 17 third quarter by the Lakers basically makes last night's game you know absolutely and there's no reason to really there's no big takeaways from last night's game is Susan turned into a blowout you know nothing really matters what happened with the Pelicans from there so the 22 minutes that Murphy saw last night I'm not worried about like you said you still the leading scorer for 14 points in those 22 minutesand anytime you was on the floor he was very aggressive on the offensive end you know he's played 2230 and 22 minutes in the three games he's returned from injury having some rest kind of being East back into the rotation champ be a big surprise but the fact that he already hit 30 minutes basically alleviates any concerns I would have will he be in the starting lineup I think that's a bigger question mark I don't Herbert Herbert Jones been playing so well for the Pelicans that I think they're gonna stick with them for at least a little while I mean they're 12 and 11 they had some assess the in-season tournament\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ''.join([segment_df.iloc[i].sentence for i in [5,6,7]])\n",
    "sentence\n",
    "\n",
    "# TODO how can topic models be used?\n",
    "# Hierarchical Dirichlet Process (HDP)\n",
    "# Latent semantic Indexing (LSI or LDI)\n",
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfbc852b-f5b6-481e-845b-ee4c7599807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: (0, '0.033*inseason + 0.029*reason + 0.028*third + 0.027*teams + 0.025*injury + 0.024*right + 0.024*still + 0.022*herbert + 0.021*basically + 0.020*know')\n",
      "Topic 2: (1, '0.046*said + 0.036*hit + 0.036*blowout + 0.029*herbert + 0.029*mentioned + 0.027*thats + 0.026*stick + 0.025*end + 0.023*theyre + 0.022*would')\n",
      "Topic 3: (2, '0.048*champ + 0.040*rest + 0.036*yeah + 0.033*points + 0.027*hes + 0.026*blowout + 0.025*makes + 0.024*quarter + 0.021*ends + 0.020*mentioned')\n",
      "Topic 4: (3, '0.063*blowout + 0.040*know + 0.035*absolutely + 0.034*well + 0.033*injury + 0.031*floor + 0.031*turned + 0.029*teams + 0.026*big + 0.024*reason')\n",
      "Topic 5: (4, '0.064*said + 0.048*rotation + 0.043*stick + 0.036*night + 0.034*lakers + 0.030*quarter + 0.028*thats + 0.026*would + 0.025*three + 0.025*happened')\n",
      "Topic 6: (5, '0.055*injury + 0.032*games + 0.031*leading + 0.027*stick + 0.026*happened + 0.026*alleviates + 0.022*yeah + 0.021*points + 0.021*pelicans + 0.021*minutes')\n",
      "Topic 7: (6, '0.058*maybe + 0.044*absolutely + 0.041*returned + 0.030*last + 0.029*hit + 0.028*injury + 0.027*though + 0.027*would + 0.027*mark + 0.024*bigger')\n",
      "Topic 8: (7, '0.060*concerns + 0.038*back + 0.036*game + 0.033*stick + 0.031*either + 0.029*already + 0.025*ends + 0.023*mentioned + 0.021*end + 0.021*like')\n",
      "Topic 9: (8, '0.079*rest + 0.049*worried + 0.035*three + 0.035*assess + 0.030*end + 0.029*hit + 0.027*gon + 0.025*anytime + 0.025*happened + 0.022*little')\n",
      "Topic 10: (9, '0.044*like + 0.038*score + 0.035*games + 0.032*quarter + 0.031*surprise + 0.027*bigger + 0.026*yeah + 0.025*fact + 0.024*im + 0.023*east')\n",
      "Topic 11: (10, '0.056*games + 0.047*hit + 0.046*basically + 0.041*played + 0.040*murphy + 0.030*score + 0.030*rest + 0.026*trey + 0.025*little + 0.020*mark')\n",
      "Topic 12: (11, '0.065*rest + 0.039*reason + 0.031*well + 0.030*dont + 0.028*assess + 0.027*back + 0.026*big + 0.024*happened + 0.022*na + 0.022*tournament')\n",
      "Topic 13: (12, '0.039*thats + 0.037*though + 0.035*theres + 0.032*tournament + 0.030*ends + 0.030*champ + 0.030*nights + 0.029*jones + 0.029*well + 0.026*coming')\n",
      "Topic 14: (13, '0.049*pokemon + 0.042*nights + 0.039*absolutely + 0.037*takeaways + 0.035*hes + 0.033*basically + 0.032*leading + 0.030*like + 0.025*lakers + 0.022*stick')\n",
      "Topic 15: (14, '0.051*points + 0.032*mean + 0.031*lakers + 0.030*absolutely + 0.028*makes + 0.028*highest + 0.027*dont + 0.025*nothing + 0.024*returned + 0.024*shannon')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.models import HdpModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by lowercasing, removing special characters,\n",
    "    tokenizing, and removing stopwords.\n",
    "    \"\"\"\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# File path to the podcast transcript\n",
    "directory_path = \"../data/raw/rotowire_2023_2024\"\n",
    "file_path = (\n",
    "    directory_path\n",
    "    + \"/Fantasy Basketball Waiver Wire - Adds for Week 8 2023-24_transcript_6b67bc46-0000-2bfc-bcc0-2405887bfb7c.txt\"\n",
    ")\n",
    "\n",
    "# Read and preprocess the text\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "\n",
    "text = sentence\n",
    "# Preprocess the text into tokenized segments\n",
    "processed_text = preprocess_text(text)\n",
    "\n",
    "# Segment the text into smaller chunks (e.g., paragraphs or 50-token chunks)\n",
    "chunk_size = 50\n",
    "chunks = [processed_text[i:i + chunk_size] for i in range(0, len(processed_text), chunk_size)]\n",
    "\n",
    "# Prepare the data for HDP\n",
    "dictionary = Dictionary(chunks)\n",
    "corpus = [dictionary.doc2bow(chunk) for chunk in chunks]\n",
    "\n",
    "# Train the HDP model\n",
    "hdp_model = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "\n",
    "# Print the discovered topics\n",
    "topics = hdp_model.print_topics(num_topics=15, num_words=10)\n",
    "for i, topic in enumerate(topics):\n",
    "    print(f\"Topic {i + 1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "664857c4-9ea5-4c26-b497-cc7c8d802de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.2795729567203427\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Compute the coherence score\n",
    "coherence_model = CoherenceModel(model=hdp_model, texts=chunks, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065d47d-0bdc-4b6a-a94a-b8c02ecff24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO better segmentation for better topic modeling?\n",
    "# TODO look at topic distributions across documents\n",
    "# TODO topic visualization in 2D space\n",
    "\n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "# import pyLDAvis\n",
    "\n",
    "# # Prepare the visualization\n",
    "# vis_data = gensimvis.prepare(hdp_model, corpus, dictionary)\n",
    "# pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a028543-4aad-4a65-8eaf-eacbac748f27",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddbd397-3f52-4939-a2d7-4caf8cfab9c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✘ No compatible package found for 'en_coreference_web_trf' (spaCy v3.8.2)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1723e8dc-f22c-48f9-b6b2-544b5122f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\multiarray.py\", line 1, in <module>\n",
      "    from numpy._core import multiarray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.fromnumeric failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp310-win_amd64.pyd)\n",
      "]\n",
      "[autoreload of numpy.core.arrayprint failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp310-win_amd64.pyd)\n",
      "]\n",
      "[autoreload of numpy.core.records failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.getlimits failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core._internal failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_internal.py\", line 1, in <module>\n",
      "    from numpy._core import _internal\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\_internal.py\", line 13, in <module>\n",
      "    from .multiarray import dtype, array, ndarray, promote_types, StringDType\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp310-win_amd64.pyd)\n",
      "]\n",
      "[autoreload of numpy.lib.mixins failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp310-win_amd64.pyd)\n",
      "]\n",
      "[autoreload of numpy.lib.scimath failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.stride_tricks failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\", line 1, in <module>\n",
      "    from ._stride_tricks_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_stride_tricks_impl.py\", line 14, in <module>\n",
      "    from numpy._core.numeric import normalize_axis_tuple\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_scalars.py:12: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  _BoolLike_co = Union[bool, np.bool]\n",
      "[autoreload of numpy._typing._scalars failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_scalars.py\", line 12, in <module>\n",
      "    _BoolLike_co = Union[bool, np.bool]\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\__init__.py\", line 324, in __getattr__\n",
      "    set(lib._utils_impl.__all__) |\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?\n",
      "]\n",
      "C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_dtype_like.py:142: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  type[np.bool],\n",
      "[autoreload of numpy._typing._dtype_like failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_dtype_like.py\", line 142, in <module>\n",
      "    type[np.bool],\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\__init__.py\", line 324, in __getattr__\n",
      "    set(lib._utils_impl.__all__) |\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?\n",
      "]\n",
      "C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_array_like.py:97: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  dtype[np.bool],\n",
      "[autoreload of numpy._typing._array_like failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_typing\\_array_like.py\", line 97, in <module>\n",
      "    dtype[np.bool],\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\__init__.py\", line 324, in __getattr__\n",
      "    set(lib._utils_impl.__all__) |\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?\n",
      "]\n",
      "[autoreload of numpy.linalg failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\linalg\\linalg.py\", line 3, in __getattr__\n",
      "    from numpy.linalg import _linalg\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\linalg\\_linalg.py\", line 25, in <module>\n",
      "    from numpy._core import (\n",
      "ImportError: cannot import name 'array' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.matrixlib.defmatrix failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\", line 8, in <module>\n",
      "    import numpy._core.numeric as N\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\format.py\", line 170, in <module>\n",
      "    from numpy.lib._utils_impl import drop_metadata\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_utils_impl.py\", line 10, in <module>\n",
      "    from numpy._core import ndarray\n",
      "ImportError: cannot import name 'ndarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.lib._iotools failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_iotools.py\", line 7, in <module>\n",
      "    import numpy._core.numeric as nx\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 1, in <module>\n",
      "    from ._npyio_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py\", line 20, in <module>\n",
      "    from numpy._core.multiarray import packbits, unpackbits\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\__init__.py\", line 13, in <module>\n",
      "    from . import array_utils\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.fft._pocketfft failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\fft\\_pocketfft.py\", line 36, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.fft failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\fft\\helper.py\", line 3, in __getattr__\n",
      "    from numpy.fft import _helper\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\fft\\_helper.py\", line 5, in <module>\n",
      "    from numpy._core import integer, empty, arange, asarray, roll\n",
      "ImportError: cannot import name 'integer' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.polyutils failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\polyutils.py\", line 27, in <module>\n",
      "    from numpy._core.multiarray import dragon4_positional, dragon4_scientific\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.polynomial.polynomial failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\polynomial.py\", line 85, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.chebyshev failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\chebyshev.py\", line 112, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.legendre failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\legendre.py\", line 84, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\hermite.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite_e failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\hermite_e.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.laguerre failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\polynomial\\laguerre.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy.ctypeslib failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\ctypeslib.py\", line 59, in <module>\n",
      "    from numpy._core.multiarray import _flagdict, flagsobj\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp310-win_amd64.pyd)\n",
      "]\n",
      "[autoreload of numpy.ma.extras failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\ma\\extras.py\", line 35, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index, normalize_axis_tuple\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\lib\\_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py)\n",
      "]\n",
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\core\\defchararray.py\", line 2, in __getattr__\n",
      "    from numpy._core import defchararray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\defchararray.py\", line 21, in <module>\n",
      "    from .numerictypes import bytes_, str_, character\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy._core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\__init__.py\", line 23, in <module>\n",
      "    from . import multiarray\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\multiarray.py\", line 84, in <module>\n",
      "    def empty_like(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "  File \"C:\\Users\\Patrick\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\numpy\\_core\\overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FCoref.__init__() got an unexpected keyword argument 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the FastCoref model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m coref_model \u001b[38;5;241m=\u001b[39m \u001b[43mFCoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbiu-nlp/f-coref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load a BERT model and tokenizer\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: FCoref.__init__() got an unexpected keyword argument 'model_name'"
     ]
    }
   ],
   "source": [
    "from fastcoref import FCoref\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the FastCoref model\n",
    "coref_model = FCoref(model_name=\"biu-nlp/f-coref\")\n",
    "\n",
    "# Load a BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_players():\n",
    "    # Replace with your logic to retrieve player names\n",
    "    return {\"LeBron James\", \"Stephen Curry\", \"Anthony Davis\"}\n",
    "\n",
    "def resolve_coreferences(text):\n",
    "    \"\"\"\n",
    "    Resolves coreferences in the text using FastCoref.\n",
    "    \"\"\"\n",
    "    doc = coref_model.predict(text, aggregation_strategy=\"average\")\n",
    "    resolved_text = doc.resolved_text\n",
    "    return resolved_text\n",
    "\n",
    "def extract_player_sentences(podcast_text, players):\n",
    "    \"\"\"\n",
    "    Extracts sentences mentioning specific players using coreference resolution.\n",
    "    \"\"\"\n",
    "    resolved_text = resolve_coreferences(podcast_text)\n",
    "    sentences = resolved_text.split(\". \")  # Simple sentence splitting\n",
    "\n",
    "    player_sentences = {player: [] for player in players}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Check if a player is mentioned directly in the sentence\n",
    "        for player in players:\n",
    "            if player in sentence:\n",
    "                player_sentences[player].append(sentence.strip())\n",
    "\n",
    "    return player_sentences\n",
    "\n",
    "def generate_player_vectors(player_sentences):\n",
    "    \"\"\"\n",
    "    Generate vector representations for each player using BERT.\n",
    "    \"\"\"\n",
    "    player_vectors = {}\n",
    "\n",
    "    for player, sentences in player_sentences.items():\n",
    "        # Tokenize and process all sentences related to the player\n",
    "        sentence_embeddings = []\n",
    "        for sentence in sentences:\n",
    "            inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = bert_model(**inputs)\n",
    "                # Use [CLS] token embedding as the representation\n",
    "                sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)\n",
    "                sentence_embeddings.append(sentence_embedding.numpy())\n",
    "\n",
    "        # Aggregate sentence embeddings for the player (mean pooling)\n",
    "        if sentence_embeddings:\n",
    "            player_vectors[player] = np.mean(sentence_embeddings, axis=0)\n",
    "        else:\n",
    "            player_vectors[player] = None  # No context found for the player\n",
    "\n",
    "    return player_vectors\n",
    "\n",
    "\n",
    "podcast_text = \"\"\"\n",
    "LeBron James played an incredible game last night, scoring 40 points. He showed great leadership on the court.\n",
    "Meanwhile, Stephen Curry impressed everyone with his three-point shooting, hitting 7 threes.\n",
    "Anthony Davis was solid on defense, but his offensive output was limited.\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve players of interest\n",
    "players = get_players()\n",
    "\n",
    "# Extract sentences mentioning each player\n",
    "player_sentences = extract_player_sentences(podcast_text, players)\n",
    "print(\"Player Sentences:\")\n",
    "for player, sentences in player_sentences.items():\n",
    "    print(f\"{player}: {sentences}\")\n",
    "\n",
    "# Generate vector representations\n",
    "player_vectors = generate_player_vectors(player_sentences)\n",
    "print(\"\\nPlayer Vectors:\")\n",
    "for player, vector in player_vectors.items():\n",
    "    print(f\"{player}: {vector}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21134433-93bc-46ac-bb30-f3767489e193",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'coref_clusters'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_player_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_players\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 36\u001b[0m, in \u001b[0;36mextract_player_sentences\u001b[1;34m(podcast_text, players)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Avoid duplicate additions\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Check for coreferential mentions\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoref_clusters\u001b[49m:  \u001b[38;5;66;03m# Coreference clusters\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(player \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(mention) \u001b[38;5;28;01mfor\u001b[39;00m player \u001b[38;5;129;01min\u001b[39;00m players \u001b[38;5;28;01mfor\u001b[39;00m mention \u001b[38;5;129;01min\u001b[39;00m cluster\u001b[38;5;241m.\u001b[39mmentions):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;66;03m# If player is coreferentially linked, add the sentence\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         player_sentences[player]\u001b[38;5;241m.\u001b[39mappend(sent\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310-ml-gpu\\lib\\site-packages\\spacy\\tokens\\underscore.py:48\u001b[0m, in \u001b[0;36mUnderscore.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extensions:\n\u001b[1;32m---> 48\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE046\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m     49\u001b[0m     default, method, getter, setter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extensions[name]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m getter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'coref_clusters'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "extract_player_sentences(text, get_players())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262ddbd-debc-45ad-b1eb-1d48aa3a8049",
   "metadata": {},
   "source": [
    "## Bert Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b28f5bd6-6557-4188-aada-fac4d84ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the podcast transcript\n",
    "directory_path = \"../data/raw/rotowire_2023_2024\"\n",
    "file_path = (\n",
    "    directory_path\n",
    "    + \"/Fantasy Basketball Waiver Wire - Adds for Week 8 2023-24_transcript_6b67bc46-0000-2bfc-bcc0-2405887bfb7c.txt\"\n",
    ")\n",
    "\n",
    "# Read and preprocess the text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b0107-eac5-4d94-9443-218725124201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5d7cb2e-8c7f-4435-9ccb-f111cc7e603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What was said about Herbert Jones performance?\n",
      "A: the thing that disturbs me is he's not a young kid\n",
      "\n",
      "Q: What was the sentiment around Herbert Jones?\n",
      "A: he's not a young kid\n",
      "\n",
      "Q: Were there any criticisms of Herbert Jones?\n",
      "A: he's got two guys on the team that are better players than him\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a QA pipeline\n",
    "# qa_pipeline = pipeline(\"question-answering\", model=\"deberta-v3-large\")\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Input context (podcast transcript)\n",
    "# context = \"LeBron James played exceptionally well last night, scoring 40 points. However, his defense was questionable...\"\n",
    "context = text\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What was said about Herbert Jones performance?\",\n",
    "    \"What was the sentiment around Herbert Jones?\",\n",
    "    \"Were there any criticisms of Herbert Jones?\"\n",
    "]\n",
    "\n",
    "# Get answers for each question\n",
    "for question in questions:\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"Q: {question}\\nA: {result['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459251ed-8565-4b02-b2c3-5516501c85db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff78731-5f76-4f5f-925a-1a75db8c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Approaches\n",
    "# If the above adjustments still seem complex, consider alternative modeling approaches:\n",
    "\n",
    "# 1. Use a Transformer-Based Model for End-to-End Analysis\n",
    "# Models like GPT or BERT-based architectures can handle NER, context understanding, and sentiment analysis jointly.\n",
    "# Fine-tune these models on annotated podcast text for:\n",
    "# Identifying players\n",
    "# Extracting context\n",
    "# Classifying sentiment directly\n",
    "# 2. Treat it as a Question-Answering Task\n",
    "# Formulate the task as:\n",
    "# \"What is the sentiment around Player X in the podcast?\"\n",
    "# Use QA models to identify the most relevant segment and its sentiment.\n",
    "# 3. Use Context-Aware Embedding Models\n",
    "# Embed the entire podcast using a context-aware model like Sentence-BERT.\n",
    "# Use similarity-based search to locate the most relevant context around a player mention and then analyze sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861558a3-50ba-407c-bca9-4a7115e28501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving Your Plan\n",
    "# Instead of completely changing your plan, you can make it \"smarter\" and more manageable by addressing the key challenges strategically:\n",
    "\n",
    "# 1. Named Entity Recognition (NER)\n",
    "# Fine-tune or use a domain-specific model:\n",
    "\n",
    "# Use pre-trained models like SpaCy or Hugging Face Transformers.\n",
    "# Fine-tune these models on basketball-related text datasets (e.g., annotated transcripts, sports news, or player rosters).\n",
    "# Incorporate a list of basketball player names:\n",
    "\n",
    "# Use external data sources like NBA rosters or fantasy basketball datasets to build a lookup table for player names.\n",
    "# Combine rule-based methods with NER:\n",
    "# Check for matches between recognized entities and your roster list.\n",
    "# Validate contextually by checking co-occurring terms like \"team,\" \"game,\" or \"points.\"\n",
    "# 2. Context Extraction\n",
    "# Dynamic Window-Based Context:\n",
    "\n",
    "# Extract a fixed-size window of text (e.g., N sentences or tokens) before and after the player mention.\n",
    "# Experiment with window sizes to balance granularity and relevance.\n",
    "# Semantic Segmentation:\n",
    "\n",
    "# Use semantic chunking techniques (like segment_by_semantics) to split the text into coherent units.\n",
    "# Identify the chunk containing the player's mention and analyze it.\n",
    "# Dependency Parsing:\n",
    "\n",
    "# Use syntactic dependency parsing to extract clauses or phrases related to the player’s name (e.g., actions or descriptors linked to the player).\n",
    "# 3. Sentiment Analysis\n",
    "# Fine-tune a Sentiment Model for Sports:\n",
    "\n",
    "# Fine-tune a sentiment analysis model on basketball-specific text to handle domain-specific nuances like sarcasm or conditional praise.\n",
    "# Example: Use Hugging Face models with labeled sentiment data from sports articles or social media.\n",
    "# Aspect-Based Sentiment Analysis (ABSA):\n",
    "\n",
    "# Train or use pre-built ABSA models to detect sentiment specifically related to the player.\n",
    "# ABSA focuses on entities (e.g., players) and their associated sentiment directly.\n",
    "# 4. Automate and Iterate\n",
    "# Use a pipeline approach to combine NER, context extraction, and sentiment analysis:\n",
    "# Perform NER to detect player mentions.\n",
    "# Extract context dynamically using a combination of window-based and semantic chunking methods.\n",
    "# Analyze sentiment on extracted context.\n",
    "# Iteratively evaluate and refine the pipeline using test cases and manually annotated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c468c44-7068-413d-8bfe-1923123a9c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah Shannon we saw like I mentioned Trey Murphy was a team's highest score for the Pelicans he still coming off the bench though  any concerns about that or do you think like either still a good chance he ends up playing 30 minutes a game off the bench maybe the Pokemon starting lineup at some point you know her Jones is still in there right now  yeah I mean that that 43 to 17 third quarter by the Lakers basically makes last night's game you know absolutely and there's no reason to really there's no big takeaways from last night's game is Susan turned into a blowout you know nothing really matters what happened with the Pelicans from there so the 22 minutes that Murphy saw last night I'm not worried about like you said you still the leading scorer for 14 points in those 22 minutesand anytime you was on the floor he was very aggressive on the offensive end you know he's played 2230 and 22 minutes in the three games he's returned from injury having some rest kind of being East back into the rotation champ be a big surprise but the fact that he already hit 30 minutes basically alleviates any concerns I would have will he be in the starting lineup I think that's a bigger question mark I don't Herbert Herbert Jones been playing so well for the Pelicans that I think they're gonna stick with them for at least a little while I mean they're 12 and 11 they had some assess the in-season tournament\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ''.join([segment_df.iloc[i].sentence for i in [5,6,7]])\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c72412b7-e1b7-4699-ad46-7ad4680beaee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuralcoref'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneuralcoref\u001b[39;00m\n\u001b[0;32m      5\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m neuralcoref\u001b[38;5;241m.\u001b[39madd_to_pipe(nlp)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neuralcoref'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(sentence)\n",
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3793db-78d9-4590-948b-f6fa153ee748",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sentence = annotate_entities([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5c949c9-bd6a-4378-9452-820fa0566946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': \"yeah Shannon we saw like I mentioned Trey Murphy was a team's highest score for the Pelicans he still coming off the bench though  any concerns about that or do you think like either still a good chance he ends up playing 30 minutes a game off the bench maybe the Pokemon starting lineup at some point you know her Jones is still in there right now  yeah I mean that that 43 to 17 third quarter by the Lakers basically makes last night's game you know absolutely and there's no reason to really there's no big takeaways from last night's game is Susan turned into a blowout you know nothing really matters what happened with the Pelicans from there so the 22 minutes that Murphy saw last night I'm not worried about like you said you still the leading scorer for 14 points in those 22 minutesand anytime you was on the floor he was very aggressive on the offensive end you know he's played 2230 and 22 minutes in the three games he's returned from injury having some rest kind of being East back into the rotation champ be a big surprise but the fact that he already hit 30 minutes basically alleviates any concerns I would have will he be in the starting lineup I think that's a bigger question mark I don't Herbert Herbert Jones been playing so well for the Pelicans that I think they're gonna stick with them for at least a little while I mean they're 12 and 11 they had some assess the in-season tournament\",\n",
       "  'entities': [('Shannon', 'FAC'),\n",
       "   ('Trey Murphy', 'PERSON'),\n",
       "   ('Pelicans', 'NORP'),\n",
       "   ('30 minutes', 'TIME'),\n",
       "   ('Pokemon', 'PERSON'),\n",
       "   ('Jones', 'PERSON'),\n",
       "   ('43 to 17 third quarter', 'DATE'),\n",
       "   (\"last night's\", 'TIME'),\n",
       "   (\"last night's\", 'TIME'),\n",
       "   ('Susan', 'PERSON'),\n",
       "   ('Pelicans', 'NORP'),\n",
       "   ('22 minutes', 'TIME'),\n",
       "   ('Murphy', 'PERSON'),\n",
       "   ('last night', 'TIME'),\n",
       "   ('14', 'CARDINAL'),\n",
       "   ('22', 'CARDINAL'),\n",
       "   ('2230 and 22 minutes', 'TIME'),\n",
       "   ('three', 'CARDINAL'),\n",
       "   ('East', 'LOC'),\n",
       "   ('30 minutes', 'TIME'),\n",
       "   ('Herbert Herbert Jones', 'PERSON'),\n",
       "   ('Pelicans', 'NORP'),\n",
       "   ('12', 'CARDINAL'),\n",
       "   ('11', 'CARDINAL')]}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c45c462-7be1-4330-8ad5-4e8cebd25c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate_entities(segment_by_semantics(sentence)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "404f308d-8ae1-4221-bc22-f57117f5ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah I mean that that 43 to 17 third quarter by the Lakers basically makes last night's game you know absolutely and there's no reason to really there's no big takeaways from last night's game is Susan turned into a blowout you know nothing really matters what happened with the Pelicans from there so the 22 minutes that Murphy saw last night I'm not worried about like you said you still the leading scorer for 14 points in those 22 minutes\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_df.iloc[6].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dc3839e-33a9-41f4-84d8-07dc40ff6c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and anytime you was on the floor he was very aggressive on the offensive end you know he's played 2230 and 22 minutes in the three games he's returned from injury having some rest kind of being East back into the rotation champ be a big surprise but the fact that he already hit 30 minutes basically alleviates any concerns I would have will he be in the starting lineup I think that's a bigger question mark I don't Herbert Herbert Jones been playing so well for the Pelicans that I think they're gonna stick with them for at least a little while I mean they're 12 and 11 they had some assess the in-season tournament\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_df.iloc[7].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae87d78-a070-4d7f-86ac-c1fc38b9bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76b3f7-6083-418f-90e1-b18ddede37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a125558-010c-47b2-ac86-fcf8c9d0dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = df.iloc[0].entities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
