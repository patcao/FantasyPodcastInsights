{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "068eb282-6a7d-4c55-b27d-09f5d735c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 400)\n",
    "\n",
    "from src.utils import get_repo_root\n",
    "\n",
    "root = get_repo_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08afac53-9472-4e14-89ce-933b55198a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load text file\n",
    "with open(\n",
    "    root\n",
    "    / \"data/raw/DG RFB Transcripts/Fantasy Basketball Waiver Wire for Week 15 2023-24_transcript.txt\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    full_text = f.readlines()[0]\n",
    "\n",
    "# Load the labels (player names)\n",
    "with open(root / \"labels.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbfa294b-f67c-4d03-8817-8c522111adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Define schema for annotations\n",
    "class Annotation(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "\n",
    "\n",
    "class ParagraphAnnotation(BaseModel):\n",
    "    annotations: list[Annotation]\n",
    "\n",
    "\n",
    "# Load a lightweight local model using Hugging Face\n",
    "# device = 0 if torch.cuda.is_available() else -1\n",
    "device = \"cpu\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "class Annotation(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "\n",
    "class ParagraphAnnotation(BaseModel):\n",
    "    annotations: list[Annotation]\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert annotator. Identify all mentions of NBA players from the given text \n",
    "and provide their start and end character positions in a structured JSON format. \n",
    "The JSON structure must strictly follow this schema:\n",
    "{format_instructions}\n",
    "\n",
    "Labels: \n",
    "{labels}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4-0-mini\", temperature=0)\n",
    "local_model = pipeline(\"text-generation\", model=\"distilgpt2\", device=device, max_length=4056)\n",
    "llm = HuggingFacePipeline(pipeline=local_model)\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ParagraphAnnotation)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"labels\", \"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "pipeline = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68797559-8f31-4ec5-a207-3c0a66f647af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import PodcastContainer\n",
    "\n",
    "pod = PodcastContainer()\n",
    "pdf = pod.get_episodes_for_podcast('rotowire')\n",
    "pdf = pdf[(pdf.publication_date >= pd.to_datetime('2023-10-24')) & (pdf.publication_date < pd.to_datetime('2023-10-30'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01248b2f-def4-4412-ba85-2565cbbc9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "597630e2-36d4-44d5-bffe-1a28405b1b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opening_week_preview_boom_or_bust_players_three_bold_fantasy_predictions'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "274bf3c1-2b04-44fd-9eb1-d6e8fc570f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "98it [00:00, ?it/s][A\n",
      "\n",
      "152it [00:00, 152011.02it/s]\n",
      "\n",
      "117it [00:00, ?it/s]A\n",
      "\n",
      "105it [00:00, ?it/s]A\n",
      "4it [00:00, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Studio annotations saved to G:\\My Drive\\Columbia\\Practical Deep Learning\\FantasyPodcastInsights\\data\\raw\\unannotated\\fantasy_basketball_waiver_wire_for_week_2_202324_raw.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "base_dir = get_repo_root() / 'data/raw/unannotated'\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx, row in tqdm(pdf.iterrows()):\n",
    "    label_studio_data = []    \n",
    "    file_name = row.file_name\n",
    "    full_text = row.content\n",
    "    \n",
    "    paragraphs = text_splitter.split_text(full_text)\n",
    "    # Generate annotations for each paragraph\n",
    "    for idx, para in tqdm(enumerate(paragraphs, start=1)):\n",
    "        try:\n",
    "            json_data = {\n",
    "                \"id\": f\"{file_name}_{idx}\",\n",
    "                \"data\": {\"text\": para}\n",
    "            }\n",
    "            label_studio_data.append(json_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paragraph {idx}: {e}\")\n",
    "\n",
    "    # Save to JSON file\n",
    "    output_path = base_dir / f\"{file_name}_raw.json\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(label_studio_data, f, indent=2)\n",
    "\n",
    "print(f\"Label Studio annotations saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809cf1e-9680-4d28-8caa-6a2373617880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annotated_json(labels, paragraph, annotation):\n",
    "\n",
    "    # Invoke the annotation pipeline\n",
    "    para_annotated = pipeline.invoke({\"labels\": labels, \"text\": para})\n",
    "\n",
    "    # Convert to Label Studio format\n",
    "    return {\n",
    "        \"id\": idx,\n",
    "        \"data\": {\"text\": paragraph},\n",
    "        \"predictions\": [\n",
    "            {\n",
    "                \"model_version\": \"model_1\",\n",
    "                \"result\": [\n",
    "                    {\n",
    "                        \"from_name\": \"label\",\n",
    "                        \"to_name\": \"text\",\n",
    "                        \"type\": \"labels\",\n",
    "                        \"value\": {\n",
    "                            \"start\": annotation.start,\n",
    "                            \"end\": annotation.end,\n",
    "                            \"labels\": [annotation.label],\n",
    "                        },\n",
    "                    }\n",
    "                    for annotation in para_annotated.annotations\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd926e68-6d77-48e7-baaa-65ea0f63afe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b754bdbd-2d33-4668-ae1f-bd2511107713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\"annotations\":[{\"start\":105,\"end\":110,\"label\":\"PLAYER\"},{\"start\":112,\"end\":118,\"label\":\"PLAYER\"},{\"start\":120,\"end\":125,\"label\":\"PLAYER\"},{\"start\":127,\"end\":134,\"label\":\"PLAYER\"},{\"start\":136,\"end\":145,\"label\":\"PLAYER\"},{\"start\":222,\"end\":226,\"label\":\"PLAYER\"},{\"start\":228,\"end\":233,\"label\":\"PLAYER\"},{\"start\":235,\"end\":237,\"label\":\"PLAYER\"},{\"start\":239,\"end\":244,\"label\":\"PLAYER\"},{\"start\":246,\"end\":250,\"label\":\"PLAYER\"},{\"start\":298,\"end\":301,\"label\":\"PLAYER\"},{\"start\":303,\"end\":309,\"label\":\"PLAYER\"},{\"start\":315,\"end\":320,\"label\":\"PLAYER\"},{\"start\":322,\"end\":327,\"label\":\"PLAYER\"},{\"start\":329,\"end\":331,\"label\":\"PLAYER\"},{\"start\":333,\"end\":339,\"label\":\"PLAYER\"},{\"start\":341,\"end\":349,\"label\":\"PLAYER\"},{\"start\":351,\"end\":354,\"label\":\"PLAYER\"},{\"start\":356,\"end\":363,\"label\":\"PLAYER\"},{\"start\":367,\"end\":372,\"label\":\"PLAYER\"}]}\\n```'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# def annotate_paragraph(paragraph, labels):\n",
    "#     prompt = (\n",
    "#         f\"You are an expert annotator. Identify all mentions of NBA players from the following text \"\n",
    "#         f'and provide their start and end character positions. Here is the text:\\n\\n\"{paragraph}\"\\n\\n'\n",
    "#         \"Labels: \" + \", \".join(labels)\n",
    "#     )\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def annotate_paragraph(paragraph, labels):\n",
    "    prompt = (\n",
    "        f\"You are an expert annotator. Identify all mentions of NBA players from the following text \"\n",
    "        f\"and provide their start and end character positions in JSON format with this structure:\\n\"\n",
    "        f'{{\"annotations\": [{{\"start\": start_position, \"end\": end_position, \"label\": \"PLAYER\"}}]}}\\n\\n'\n",
    "        \"Do not output any comments. Only output valid json\"\n",
    "        f'Here is the text:\\n\\n\"{paragraph}\"\\n\\n'\n",
    "        \"Labels: \" + \", \".join(labels)\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    # Parse response content\n",
    "    return response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        return json.loads(structured_json)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"LLM response is not valid JSON.\")\n",
    "\n",
    "\n",
    "r = annotate_paragraph(paragraphs[0], labels)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b7c971-109e-4915-b7de-c0ffc359d409",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 837 (char 836)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:105,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:110,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:112,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:118,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:120,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:125,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:127,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:134,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:136,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:145,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:222,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:226,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:228,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:233,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:235,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:237,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:239,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:244,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:246,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:250,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:298,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:301,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:303,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:309,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:315,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:320,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:322,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:327,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:329,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:331,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:333,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:339,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:341,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:349,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:351,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:354,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:356,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:363,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:367,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:372,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAYER\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310-nlp\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310-nlp\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310-nlp\\lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 837 (char 836)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71691854-bdd8-4399-b4c7-13a59ea368fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m annotations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, paragraph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(paragraphs):\n\u001b[1;32m---> 15\u001b[0m     llm_response \u001b[38;5;241m=\u001b[39m \u001b[43mannotate_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Parse LLM output (ensure it matches your required format)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     spans \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(llm_response)\n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m, in \u001b[0;36mannotate_paragraph\u001b[1;34m(paragraph, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannotate_paragraph\u001b[39m(paragraph, labels):\n\u001b[0;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert annotator. Identify all mentions of NBA players from the following text \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand provide their start and end character positions. Here is the text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparagraph\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(labels)\n\u001b[0;32m      6\u001b[0m     )\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310-nlp\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# Annotate paragraphs\n",
    "annotations = []\n",
    "for idx, paragraph in enumerate(paragraphs):\n",
    "    llm_response = annotate_paragraph(paragraph, labels)\n",
    "    # Parse LLM output (ensure it matches your required format)\n",
    "    spans = json.loads(llm_response)\n",
    "    annotations.append(\n",
    "        {\n",
    "            \"id\": idx + 1,\n",
    "            \"text\": paragraph.strip(),\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"result\": [\n",
    "                        {\n",
    "                            \"from_name\": \"label\",\n",
    "                            \"to_name\": \"text\",\n",
    "                            \"type\": \"labels\",\n",
    "                            \"value\": {\n",
    "                                \"start\": span[\"start\"],\n",
    "                                \"end\": span[\"end\"],\n",
    "                                \"labels\": [\"PLAYER\"],\n",
    "                            },\n",
    "                        }\n",
    "                        for span in spans\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Save to a JSON file\n",
    "output_path = root / \"/data/preannotated_transcript_label_studio.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(annotations, f, indent=4)\n",
    "\n",
    "print(f\"Pre-annotated data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
